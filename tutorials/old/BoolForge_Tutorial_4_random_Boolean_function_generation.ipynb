{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623ed82c",
   "metadata": {},
   "source": [
    "\n",
    "# BoolForge Tutorial #4: Random Boolean function generation\n",
    "\n",
    "This tutorial focuses on the random generation of Boolean functions with defined properties, which enables a wealth of computational studies. \n",
    "\n",
    "## What you will learn:\n",
    "You will learn how to generate random n-input Boolean functions under flexible constraints, including:\n",
    "\n",
    "- specified canalizing properties (canalizing depth, canalizing layer structure, etc),\n",
    "- bias, absolute bias or a specific Hamming weight,\n",
    "- linearity requirements,\n",
    "- degeneracy requirements.\n",
    "\n",
    "To ensure familiarity with these concepts, we highly recommended to first work the previous tutorials.\n",
    "\n",
    "---\n",
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cbbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boolforge\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c770b69",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 1. Generate random Boolean functions\n",
    "The function `boolforge.random_function(n,*args)` is the only function needed to be called (correctly) to generate a random Boolean function under specific constraints. Apart from the degree `n`, it takes a number of optional arguments that specify these constraints. By default, this function creates an n-input non-degenerate Boolean function. In other words, the generated function actually depends on all its inputs, i.e., each input's activity and edge effectiveness is strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "f = boolforge.random_function(n)\n",
    "\n",
    "boolforge.display_truth_table(f,labels='f_random_non_degenerate')\n",
    "\n",
    "print('Is f degenerate?',f.is_degenerate())\n",
    "print('Activities of the variables of f:',f.get_activities(EXACT=True))\n",
    "print(f'Edge effectiveness of the variables of f: {f.get_edge_effectiveness()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cde49",
   "metadata": {},
   "source": [
    "\n",
    "The rest of this tutorial describes the various constraints. Each constraint defines a specific family of n-input Boolean functions, from which `boolforge.random_function(n,*args)` samples *uniformly at random*. In other words, `boolforge.random_function(n,*args)` selects each function satisfying a given set of constraints with equal probability.\n",
    "\n",
    "---\n",
    "## 2. Linear functions\n",
    "\n",
    "If we set the optional argument `LINEAR=True`, the generated function is a linear function (also known as parity or XOR function), which we can verify by computing the activities or edge effectiveness of its inputs (all 1), or the normalized average sensitivity (1) or the canalizing strength (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = boolforge.random_function(n,LINEAR=True)\n",
    "\n",
    "boolforge.display_truth_table(f,labels='f_linear')\n",
    "\n",
    "print('Activities of the variables of f:',f.get_activities(EXACT=True))\n",
    "print(f'Edge effectiveness of the variables of f: {f.get_edge_effectiveness()}')\n",
    "print('Normalized average sensitivity of f:',f.get_average_sensitivity(EXACT=True))\n",
    "print(f'Canalizing strength of f: {f.get_canalizing_strength()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360dc662",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 3. Functions with defined canalizing properties\n",
    "\n",
    "If `LINEAR=False` (the default), we can specify the canalizing layer structure `layer_structure`. This specifies the number of conditionally canalizing variables in each layer of the randomly generated function. If the optional argument `EXACT_DEPTH=True` (default is False), then this describes the exact layer structure, i.e., the core function cannot be canalizing. If `EXACT_DEPTH=False` (the default), it is possible that the core function is canalizing, meaning that the last described layer in `layer_structure` may have more conditionally canalizing variables, or that there are additional canalizing layers. \n",
    "\n",
    "Before generating any random function, `random_function()` goes through a number of checks ensuring that the provided optional arguments make sense. For example, it checks that the provided layer structure $(k_1,\\ldots,k_r)$ satisfies\n",
    "- $k_i\\geq 1$, \n",
    "- $k_1 + \\cdots + k_r \\leq n$, and\n",
    "- if $k_1 + \\cdots + k_r = n$, then $k_r \\geq 2$ because the last layer of a nested canalizing function must always contain two or more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dec21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random canalizing function\n",
    "f = boolforge.random_function(n,layer_structure=[1])\n",
    "\n",
    "# a random function with exact canalizing depth 1\n",
    "g = boolforge.random_function(n,layer_structure=[1],EXACT_DEPTH=True)\n",
    "\n",
    "# a random nested canalizing function with one layer\n",
    "h = boolforge.random_function(n,layer_structure=[3])\n",
    "\n",
    "# a random nested canalizing function with two layers\n",
    "k = boolforge.random_function(n,layer_structure=[1,2])\n",
    "\n",
    "labels = ['f','g','h','k']\n",
    "\n",
    "boolforge.display_truth_table(f,g,h,k,labels=labels)\n",
    "\n",
    "for func,label in zip([f,g,h,k],labels):\n",
    "    canalizing_info = func.get_layer_structure()\n",
    "    print(f'Canalizing depth of {label}: {func.get_canalizing_depth()}')     \n",
    "    print(f'Layer structure of {label}: {canalizing_info['LayerStructure']}')\n",
    "    print(f'Number of canalizing layers of {label}: {canalizing_info['NumberOfLayers']}')\n",
    "    print(f'Non-canalizing core function of {label}: {canalizing_info['CoreFunction']}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bcc0f",
   "metadata": {},
   "source": [
    "\n",
    "Repeated evaluation of this block of code shows that the canalizing depth of `f` is either 1 or 3 (note that a canalizing depth of $n-1$ is never possible for a non-degenerate function). On the contrary, the canalizing depth of `g` is always 1 because we set `EXACT_DEPTH=True`. The 2-input core function of `g` is one of the two linear functions, each with 50% probability. Likewise, the core function for the other functions is simply [0] or [1], each with 50% probability. Functions `h` and `k` are nested canalizing, i.e., their canalizing depth is 3. Their layer structure is exactly as specified.\n",
    "\n",
    "If we do not care about the specific layer structure but only about the canalizing depth, we specify the optional argument `depth` instead of `layer_structure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any function has at least canalizing depth 0 so this is the same as boolforge.random_function(n)\n",
    "f = boolforge.random_function(n,depth=0)\n",
    "\n",
    "#a random non-canalizing function\n",
    "g = boolforge.random_function(n,depth=0,EXACT_DEPTH=True)\n",
    "\n",
    "#a random canalizing function\n",
    "h = boolforge.random_function(n,depth=1)\n",
    "\n",
    "#a random nested canalizing function\n",
    "k = boolforge.random_function(n,depth=n)\n",
    "\n",
    "labels = ['f','g','h','k']\n",
    "\n",
    "boolforge.display_truth_table(f,g,h,k,labels=labels)\n",
    "\n",
    "for func,label in zip([f,g,h,k],labels):\n",
    "    canalizing_info = func.get_layer_structure()\n",
    "    print(f'Canalizing depth of {label}: {func.get_canalizing_depth()}')     \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cf927",
   "metadata": {},
   "source": [
    "\n",
    "As before, repeated evaluation of this block of code shows that the canalizing depth of `f` can be 0, 1, or 3. Note that specifying `depth=0` without `EXACT_DEPTH=True` does not restrict the space of functions at all. On the contrary, the canalizing depth of `g` is always 0 (i.e., g does not contain any canalizing variables) because we set `EXACT_DEPTH=True`. Function `h` is canalizing and may be nested canalizing (because we specified that the minimal canalizing depth is 1), and `k` is always nested canalizing (i.e., it has canalizing depth $n=3$).\n",
    "\n",
    "## 4. Allowing degenerate functions \n",
    "\n",
    "It is possible that an n-input Boolean function does not depend on all its variables. For example, the function $f(x,y) = x$ depends on $x$ but not on $y$. By default, such degenerate functions are never generated by `boolforge.random_function()`. To enable the generation of possibly degenerate functions, we set `ALLOW_DEGENERATE_FUNCTIONS=True`. Although hardly of any practical value, we can even restrict the random generation to degenerate functions only, using `boolforge.random_degenerate_function(n,*args)`. \n",
    "\n",
    "Since degenerate functions occur much more frequently at low degree, we set `n=2`, generate a large number of random, possibly degenerate functions and compare a histogram of the observed number of essential variables to the expected proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "nsim = 10000\n",
    "count_essential_variables = np.zeros(n+1,dtype=int)\n",
    "for _ in range(nsim):\n",
    "    f = boolforge.random_function(n,ALLOW_DEGENERATE_FUNCTIONS=True)\n",
    "    count_essential_variables[f.get_number_of_essential_variables()] += 1\n",
    "\n",
    "#2 constant \"2-input\" functions, 4 1-variable \"2-input\" functions, 10 non-degenerate 2-input functions\n",
    "expected_proportions = [2/16,4/16,10/16] \n",
    "\n",
    "x = np.arange(n+1)\n",
    "width = 0.4\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.bar(np.arange(n+1)-width/2,count_essential_variables/nsim,width=width,label='observed')\n",
    "ax.bar(np.arange(n+1)+width/2,expected_proportions,width=width,label='expected')\n",
    "ax.legend(frameon=False,loc='best')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel('Number of essential variables')\n",
    "ax.set_ylabel(f'Proportion of {n}-input functions')\n",
    "\n",
    "print('Error:',count_essential_variables/nsim - expected_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25840f7",
   "metadata": {},
   "source": [
    " \n",
    "---\n",
    "## 5. Functions with specific Hamming weight\n",
    "\n",
    "The Hamming weight of a Boolean function is the number of 1s in its truth table. BoolForge allows for the generation of random n-input functions with a specific Hamming weight $w\\in\\{0,1,\\ldots,2^n\\}$. The additional optional parameters `ALLOW_DEGENERATE_FUNCTIONS` and `EXACT_DEPTH` specify whether degenerate and canalizing functions are allowed. By default, canalizing functions are allowed, while degenerate functions are not. Since all functions with Hamming weight $w\\in\\{0,1,2^n-1,2^n\\}$ are canalizing, we require $2\\leq w\\leq 2^n-2$ whenever canalizing functions are not permissible (i.e., whenever`EXACT_DEPTH=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efdf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "\n",
    "#a random 3-input function with Hamming weight 5\n",
    "f = boolforge.random_function(n,hamming_weight=5)\n",
    "\n",
    "#a random non-canalizing 3-input function with Hamming weight 5\n",
    "g = boolforge.random_function(n,hamming_weight=5,EXACT_DEPTH=True)\n",
    "\n",
    "#a random, possibly degenerate function with Hamming weight 2\n",
    "h = boolforge.random_function(n,hamming_weight=2,ALLOW_DEGENERATE_FUNCTIONS=True)\n",
    "\n",
    "\n",
    "labels = ['f','g','h']\n",
    "\n",
    "boolforge.display_truth_table(f,g,h,labels=labels)\n",
    "\n",
    "for func,label in zip([f,g,h],labels):\n",
    "    canalizing_info = func.get_layer_structure()\n",
    "    print(f'Hamming weight of {label}: {func.get_hamming_weight()}')     \n",
    "    print(f'Canalizing depth of {label}: {func.get_canalizing_depth()}')     \n",
    "    print(f'Number of essential variables of {label}: {func.get_number_of_essential_variables()}')     \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83e529",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 6. Biased functions\n",
    "\n",
    "While specifying the Hamming weight fixes the exact number of 1s in the truth table of a generated function, specifying the bias or absolute bias acts slightly differently. The bias $p$ describes the probability of selecting a 1 at any position in the truth table and can be modified using the optional argument `bias`. Instead of specifying the bias, the absolute bias may also be specified. Unbiased functions generated using $p=0.5$ have an absolute bias of $0$, the default. If, for example, we set `absolute_bias=0.5` and specify to use absolute bias (`USE_ABSOLUTE_BIAS=True`, default is False), the bias used to generate the function is either 0.25 or 0.75, both with probability 50%. Generally, if we set `USE_ABSOLUTE_BIAS=True; absolute_bias=a` for $a\\in [0,1]$, the bias is either $(1+a)/2$ or $(1-a)/2$, both with probability 50%. \n",
    "\n",
    "To display these different modes, we repeatedly generate random Boolean functions under three different constraints (`f` with bias $p=0.75$, `g` with absolute bias 0.5, and `h` an unbiased function, i.e., with bias $p=0.5$), and compare the empirical Hamming weight distribution of the three families of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ce2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "\n",
    "nsim = 10000\n",
    "count_hamming_weights = np.zeros((3,2**n+1),dtype=int)\n",
    "for _ in range(nsim):\n",
    "    #a random 3-input function with bias p=0.75\n",
    "    f = boolforge.random_function(n,bias=0.75)\n",
    "\n",
    "    #a random 3-input function with absolute bias 0.5 (i.e., bias p=0.25 or p=0.75)\n",
    "    g = boolforge.random_function(n,absolute_bias=0.5,USE_ABSOLUTE_BIAS=True)\n",
    "\n",
    "    #a random 3-input function with absolute bias 0.5 (but the absolute_bias is erroneously not used because USE_ABSOLUTE_BIAS=True is missing)\n",
    "    h = boolforge.random_function(n,absolute_bias=0.5)\n",
    "\n",
    "    count_hamming_weights[0,f.get_hamming_weight()] += 1\n",
    "    count_hamming_weights[1,g.get_hamming_weight()] += 1\n",
    "    count_hamming_weights[2,h.get_hamming_weight()] += 1\n",
    "\n",
    "labels=['bias 0.75','absolute bias 0.5','random']\n",
    "\n",
    "x = np.arange(2**n+1)\n",
    "width = 0.3\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for i,label in enumerate(labels):\n",
    "    ax.bar(x-width+width*i,count_hamming_weights[i]/nsim,width=width,label=labels[i])\n",
    "ax.legend(frameon=False,loc='best')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel('Hamming weight')\n",
    "ax.set_ylabel(f'Proportion of {n}-input functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fd470",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This plot exemplifies the difference between bias and absolute bias: Specifying the bias shifts the mode of the Hamming weight distribution to the value of `bias`. Specifying the absolute bias yields random functions with a bimodal Hamming weight distribution. Note that `absolute_bias=0.5` is ignored in the generation of `h`. The desired use of absolute bias must be specified by `USE_ABSOLUTE_BIAS=True`.\n",
    "\n",
    "In the above plot, we notice a lack of functions with Hamming weight 0 and $16=2^n$. These constant functions are degenerate and thus not generated unless we set `ALLOW_DEGENERATE_FUNCTIONS=True`, which as we see below slightly modifies the resulting Hamming weight distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = 10000\n",
    "count_hamming_weights = np.zeros((3,2**n+1),dtype=int)\n",
    "for _ in range(nsim):\n",
    "    #a random 3-input function with bias p=0.75\n",
    "    f = boolforge.random_function(n,bias=0.75,ALLOW_DEGENERATE_FUNCTIONS=True)\n",
    "\n",
    "    #a random 3-input function with absolute bias 0.5 (i.e., bias p=0.25 or p=0.75)\n",
    "    g = boolforge.random_function(n,absolute_bias=0.5,USE_ABSOLUTE_BIAS=True,ALLOW_DEGENERATE_FUNCTIONS=True)\n",
    "\n",
    "    #a random 3-input function with absolute bias 0.5 (but the absolute_bias is erroneously not used  because USE_ABSOLUTE_BIAS=True is missing)\n",
    "    h = boolforge.random_function(n,absolute_bias=0.5,ALLOW_DEGENERATE_FUNCTIONS=True)\n",
    "\n",
    "    count_hamming_weights[0,f.get_hamming_weight()] += 1\n",
    "    count_hamming_weights[1,g.get_hamming_weight()] += 1\n",
    "    count_hamming_weights[2,h.get_hamming_weight()] += 1\n",
    "\n",
    "labels=['bias 0.75','absolute bias 0.5','random']\n",
    "\n",
    "x = np.arange(2**n+1)\n",
    "width = 0.3\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for i,label in enumerate(labels):\n",
    "    ax.bar(x-width+width*i,count_hamming_weights[i]/nsim,width=width,label=labels[i])\n",
    "ax.legend(frameon=False,loc='best')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xlabel('Hamming weight')\n",
    "ax.set_ylabel(f'Proportion of {n}-input functions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe7160",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 5. Summary, interpretation, and outlook\n",
    "\n",
    "*Summary:* This tutorial demonstrated how BoolForge enables the uniform random generation of Boolean functions under flexible constraints on structure (canalization, degeneracy, linearity) and statistics (Hamming weight, bias, absolute bias).\n",
    "\n",
    "*Interpretation:* Different constraints correspond to fundamentally different ensembles of Boolean functions. For example:\n",
    "- fixing canalizing depth controls hierarchical decision structure,\n",
    "- fixing Hamming weight controls output sparsity,\n",
    "- fixing bias or absolute bias controls global asymmetry,\n",
    "- excluding degeneracy ensures that all variables remain dynamically relevant.\n",
    "\n",
    "Being explicit about these choices is essential when interpreting computational results, as different ensembles can yield qualitatively different dynamical behavior.\n",
    "\n",
    "*Outlook:* In the next tutorial, these function-level ensembles are used as building blocks for more advanced analyses of the link between structural and dynamical features of Boolean functions.\n",
    "\n",
    "---\n",
    "## 6. Common pitfalls\n",
    "\n",
    "- Specifying `absolute_bias` has no effect unless `USE_ABSOLUTE_BIAS=True` is set.\n",
    "- Setting `depth=0` without `EXACT_DEPTH=True` does not restrict the function space.\n",
    "- Constant functions (Hamming weight $0$ or $2^n$) are only generated when `ALLOW_DEGENERATE_FUNCTIONS=True`.\n",
    "- For larger $n$, exact verification of some properties (e.g., activities or sensitivity) may become computationally expensive; consider approximate methods when appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
